{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multielectrode Data\n",
    "\n",
    "\n",
    "\n",
    "We're going to load in the multielectrode array data from a CSV file and work with the multielectrode data in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "The data used here are from a study published by Snyder, Morais, Willis, and Smith (2015). The goal of the study was to relate neural activity across different scales, from single unit (single neuron) to whole-brain networks. To do this, the researchers simultaneously recorded neural activity from a 96-electrode array implanted in the brain, and EEG electrodes on the scalp, of rhesus macaque monkeys. Here we will work with only the 96 electrode invasive recordings, and not the EEG. Of interest is spike count correlation, which is a measure of neural functional connectivity. Functional connectivity is of widespread interest in neuroscience, and essentially refers to correlations in activity between different brain areas. If different brain areas (or individual neurons) show correlated activity, it is likely that they work together in some way. This is particularly true if their functional connectivity changes as a result of experimental manipulations. For example, if two areas (or neurons) show stronger correlation during a particular task than during a control condition, then we might infer that their functional connectivity is related to their involvement in the experimental task. Indeed, in their introduction Snyder and colleagues note that spike count correlations are structured and modulated by both perceptual and cognitive manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording\n",
    "The data were recorded from a Utah intracortical multielectrode electrode array (Maynard, Nordhausen, & Normann, 1997) implanted in area V4 of the visual cortex. \n",
    "Utah array is a type of microelectrode array consisting of a 10 x 10 grid of silicon microelectrodes that can be placed directly on the cortical surface of a living animal, covering an area of approximately 16 mm2. Each electrode is ~1 mm long, and the tip of each electrode records electrical voltage. In general, the electrodes do not penetrate individual neurons (and if they do, they likely destroy those cells), and so each electrode records signals from a small population of surrounding neurons. The strength of the electrical signals measured by the electrodes drops off with the inverse of the distance from it (i.e., 1/distance). This has two important implications:\n",
    "\n",
    "Each electrode is spaced far enough apart that it will generate a unique measurement from other electrodes, because the signal strength drops off rapidly with distance.\n",
    "\n",
    "However, because the electrodes are still relatively close together, and neurons will be located between electrodes, the spiking activity of any single neuron will typically be detected by more than one electrode.\n",
    "\n",
    "Because we are interested in the behavior of neurons, not in anything inherent about the electrodes used for measurement, it is common practice to apply spike sorting to multiunit data. This is a mathematical process that takes microelectrode array data as input, and returns as output the spike times for individual neurons. Spike sorting is applied to the data after recording, to create separate spike trains for each neuron.\n",
    "\n",
    "Spike sorting is a form of inverse problem, meaning that there are many possible solutions, and so the results of spike sorting are dependent on the algorithm used, and may not be entirely accurate. Nonetheless, spike sorting algorithms at this point are well-established and reasonably trustworthy. In the present data, spike sorting has already been performed, so the data are treated as coming from individual neurons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Data retrieval\n",
    "import os, requests\n",
    "\n",
    "fname = \"data.zip\"\n",
    "url = \"https://osf.io/kftxc/download\"\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    if not os.path.isfile(fname):\n",
    "      try:\n",
    "        r = requests.get(url)\n",
    "      except requests.ConnectionError:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "      else:\n",
    "        if r.status_code != requests.codes.ok:\n",
    "          print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "          with open(fname, \"wb\") as fid:\n",
    "            fid.write(r.content)\n",
    "    !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set known experiment parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# times the stimulus went on and off\n",
    "trial_start_time = -0.150\n",
    "grating_on_time  = 0.0\n",
    "grating_off_time = 2.0\n",
    "trial_end_time   = 2.5\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times the stimulus went on and off\n",
    "trial_start_time = -0.150\n",
    "grating_on_time  = 0.0\n",
    "grating_off_time = 2.0\n",
    "trial_end_time   = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "df = pd.read_csv('data/multielectrode_data.csv')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data \n",
    "\n",
    "\n",
    "These data are again in **long format**, and they are sparse data with one row for each spike. Let's look at the head of the data to get oriented:\n",
    "~~~python\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are:\n",
    "- channel — which electrode the data came from\n",
    "- time — spike time, relative to stimulus onset (so we have negative values for spikes that occurred during the fixation period prior to stimulus onset). This is measured in seconds\n",
    "- orientation — of stimulus (0 or 90 deg)\n",
    "- trial number — 1150 trials for each orientation\n",
    "\n",
    "We can see how many rows there are in the DataFrame (as well as the number of columns, but we could already see that in this case):\n",
    "~~~python\n",
    "df.shape\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Electrodes\n",
    "Let's see how many electrodes we have data from, and what their labels are. We save each as a variable, which will come in handy later in looping through these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "num_chan = len(df['channel'].unique())\n",
    "print('Number of electrodes (channels): ' + str(num_chan))\n",
    "\n",
    "channels = sorted(df['channel'].unique())  # use the sorted() function so the channels are listed sequentially\n",
    "print('Channel labels: ' + str(channels))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit weird — we're told this is a 96 electrode array, but there are only 20 electrodes?!  \n",
    "\n",
    "This is because the full data set is huge, with over 2 million rows. The amount of memory that this requires makes doing anything with the data quite slow. So we've provided data for a subset of channels for the purposes of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientations\n",
    "What about orientations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "orientations = sorted(df['orientation'].unique())\n",
    "num_ortns = len(orientations)\n",
    "print('Found ' + str(num_ortns) + ' orientations, which are: ' + str(orientations))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "df.shape[0] / 20 / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting repeated trials for 1 channel \n",
    "```python\n",
    "mask = (df.loc[:, 'orientation'] == 0.0) & (df.loc[:, 'channel'] == 42.0)\n",
    "new_df = df[mask]\n",
    "trials = new_df['trial'].unique()\n",
    "neural_data = []\n",
    "for trial in trials: \n",
    "    trial_data = new_df[new_df['trial'] == trial]['time'].values\n",
    "    neural_data.append(trial_data) \n",
    "len(neural_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick digression into matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://matplotlib.org/stable/_static/logo2_compressed.svg' alt='Matplotlib' width=225>\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/) is, effectively, the core plotting and data visualization package in Python. Many other packages use Matplotlib for data visualization, including pandas, NumPy, and SciPy. Matplotlib is not the only visualization package in Python, by any means. There are many others, including [seaborn](https://seaborn.pydata.org), [Altair](https://altair-viz.github.io), [ggpy](http://yhat.github.io/ggpy/), [Bokeh](https://docs.bokeh.org/en/latest/index.html), and [plot.ly](https://plot.ly). Some of the others are actually built on top of Matplotlib, but simply the syntax for creating specific, complex types of graphics relative to what's required in Matplotlib (these are called **wrappers** for Matplotlib). Others are entirely independent. Regardless, Matplotlib is the most widely-used and flexible package for data visualization in Python, and so it's valuable to learn it first, and then build out your skills from there. \n",
    "\n",
    "Matplotlib is also a very mature Python package, having been first released in 2003 and continuously updated since then. It has a strong development community, a detailed website with extensive documentation and many examples, and there is copious third party documentation in the form of blog posts, books, and more — much of which is freely available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Matplotlib\n",
    "\n",
    "We have previously covered how to import a Python package using the `import` command. We also covered how to import a package with an alias, using the syntax `import [pacakge] as [alias]` \n",
    "\n",
    "For Matplotlib, we will do this again, but we add an extra detail: Matplotlib, like many Python packages, is organized into a number of \"modules\" (essentially subsets of functions). The one that you will typically want to import for plotting is called `pyplot`. So we use the syntax below:\n",
    "\n",
    "~~~python\n",
    "import matplotlib.pyplot as plt\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Plot\n",
    "Now we can draw a simple line plot using the `matplotlib.pyplot`'s `plot()` function, by creating two lists of data points (each 4 elements long), which represent time elapsed and distance traveled by some hypothetical object:\n",
    "\n",
    "~~~python\n",
    "x = np.linspace(-np.pi,np.pi,100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sine curve');\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specifying axes limits\n",
    "```python \n",
    "x = np.linspace(-np.pi,np.pi,100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sine curve')\n",
    "plt.xlim([0,3])\n",
    "plt.ylim([-0.5,1.5]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setting ticks on axes\n",
    "```python \n",
    "x = np.linspace(-np.pi,np.pi,100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sine curve')\n",
    "plt.xticks([-2,0,2])\n",
    "plt.yticks([-1,0,1]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Controlling the color, linewidth and line type of plots <br>\n",
    "Built-in color coding <br>\n",
    "b: blue\n",
    "g: green\n",
    "r: red\n",
    "c: cyan\n",
    "m: magenta\n",
    "y: yellow\n",
    "k: black\n",
    "w: white <br>\n",
    "Specify the RGB values using tuples (r, g, b) or give the RGB hex color code\n",
    "```python\n",
    "linestyles = ['-', \"--\", \":\"]\n",
    "\n",
    "x = np.linspace(-np.pi,np.pi,100)\n",
    "\n",
    "plt.plot(x, np.sin(x), c = (1,0,0), ls = linestyles[1], linewidth=3.0)\n",
    "plt.plot(x, np.cos(x), c = (0,1,0), ls = linestyles[2], linewidth=1.0)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Basic plotting')\n",
    "plt.xticks([-2,0,2])\n",
    "plt.yticks([-1,0,1]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Adding figure legends_ <br>\n",
    "Add 'label' attribute and value to plt.plot(), e.g., plt.plot(x,y, label=\"Plot A\") <br>\n",
    "Add plt.legend(): An optional yet important attribute for this function is loc. Example values for loc include \"upper right\", \"lower center\", \"center\" etc. <br>\n",
    "For other attributes, check: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html <br>\n",
    "Optionally, size of legend can be changed using prop keyword: e.g., plt.legend(prop={'size': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "linestyles = ['-', \"--\", \":\"]\n",
    "\n",
    "x = np.linspace(-np.pi,np.pi,100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x, y, c = (1,0,0), ls = linestyles[1], label = \"sin(x)\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc=\"upper left\", prop={'size': 20})\n",
    "plt.title('Sine curve')\n",
    "plt.xticks([-2,0,2])\n",
    "plt.yticks([-1,0,1]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to neural data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def plot_raster(neural_data):\n",
    "    '''\n",
    "    Takes a dataframe containing the units group of a nwb file (units_df) and creates \n",
    "    a raster plot with a given set of neurons (indexed by neuron_start, neuron_end) and a start and end time.\n",
    "    '''\n",
    "    \n",
    "    num_trials = len(neural_data) # Calculate # of neurons\n",
    "    my_colors = ['C{}'.format(i) for i in range(num_trials)]  #Generate a list of colors (C0, C1...)\n",
    "    \n",
    "    plt.eventplot(neural_data, colors=my_colors)  # Plot our raster plot \n",
    "\n",
    "    #plt.xlim([start_time,end_time]) # Set axis limits to only include points in our data\n",
    "    \n",
    "    # Label our figure \n",
    "    plt.title('Spike raster plot')\n",
    "    plt.ylabel('Trial #')\n",
    "    plt.xlabel('Time (s)')\n",
    "    #plt.yticks()\n",
    "    plt.show()\n",
    "\n",
    "# Use our new function\n",
    "plot_raster(neural_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset and some parts of this notebook are adapted from Wallisch, Neural Data Science"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
