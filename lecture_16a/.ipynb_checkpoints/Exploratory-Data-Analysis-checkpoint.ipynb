{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71c8722-fdf7-46e0-b984-c10d3fc56e96",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2558c-7f40-462a-9f9b-c70dc6d4cfd1",
   "metadata": {},
   "source": [
    "### What makes data “good”?\n",
    "\n",
    "What makes a good data set?\n",
    "\n",
    "-   **Size**: the more *samples* are in the data set, the more examples\n",
    "    your machine learning model will be able to learn from, and the\n",
    "    better it will do. Often, a simple machine learning model trained on\n",
    "    a large data set will outperform a “fancy” model on a small data\n",
    "    set. Sample size is also crucial in statistical inference because it directly impacts the reliability and precision of your conclusions\n",
    "-   **Quality**: Are no\n",
    "    values (or very few values) missing, noisy, or incorrect? In a machine learning context, are there *predictive* features in the data?\n",
    "    Is the\n",
    "    scenario in which the data collected similar to the scenario in\n",
    "    which your model will be used? These are examples of questions that\n",
    "    we might ask to evaluate the quality of a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec0511-a645-48bb-977e-d786e21d0a7c",
   "metadata": {},
   "source": [
    "### Purpose of exploratory data analysis\n",
    "\n",
    "Once we have identified one or more candidate data sets for a particular\n",
    "problem, we perform some *exploratory data analysis*. This process helps\n",
    "us\n",
    "\n",
    "-   detect and possibly correct mistakes in the data\n",
    "-   check our assumptions about the data\n",
    "-   identify potential relationships between features\n",
    "-   assess the direction and rough size of relationships between\n",
    "    features and the target variable \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c61efc-4827-4b4d-a1c8-625533ff9407",
   "metadata": {},
   "source": [
    "“Recipe” for exploratory data analysis\n",
    "--------------------------------------\n",
    "\n",
    "We will practice using a basic “recipe” for exploratory data analysis.\n",
    "\n",
    "1.  Set down *expectations* about the data\n",
    "2.  Load data and check that it is loaded correctly\n",
    "3.  Inspect the data to make sure it is consistent with your\n",
    "    expectations (“sanity checks”), and clean or filter the data if\n",
    "    needed\n",
    "4.  Compute descriptive statistics and explore relationships in the data \n",
    "\n",
    "Every exploratory data analysis is different, as specific\n",
    "characteristics of the data may lead you to explore different things in\n",
    "depth. However, this “recipe” can be a helpful starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6672035-b3c6-479d-82a9-83effaae8e5c",
   "metadata": {},
   "source": [
    "### Set down *expectations* about the data\n",
    "\n",
    "The first step is to codify your expectations about the data *before*\n",
    "you look at it:\n",
    "\n",
    "-   Read the data documentation\n",
    "-   How many rows and columns are in the data?\n",
    "-   What does each variable mean? What units are data recorded in? What\n",
    "    is the expected range or typical value for each column? What about variability?\n",
    "-   How was data collected? Identify sampling issues etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca3b76-2ce2-4d48-8aa2-ea065c496395",
   "metadata": {},
   "source": [
    "### Example: Flanker reaction time data set\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627ab90-bf51-4a3b-8587-dc31fc5fc2ec",
   "metadata": {},
   "source": [
    "We will practice applying the “recipe” for exploratory data analysis to this data.\n",
    "\n",
    "We will use the pandas library in Python, which includes many powerful utilities for managing data. \n",
    "\n",
    "This is real data from a flanker experiment. In this experiment, participants had to press either the left or right arrow key, to indicate whether an arrow shown on the screen is pointing left or right, respectively. However, the catch is that the centre arrow is \"flanked\" by two other arrows on each side; these can be pointing the same way as the target arrow (congruent).\n",
    "\n",
    "![flanker_congruent](images/flanker_congruent@0.75x.png)\n",
    "\n",
    "or in the opposite direction (incongruent)\n",
    "\n",
    "![flanker_incongruent](images/flanker_incongruent@0.75x.png)\n",
    "\n",
    "We expect that the incongruent condition would be associated with slower RTs, because the flanking arrows create some visual confusion and response competition (cognitive interference). In order to confirm this hypothesis, we would want to get an estimate of the RT for each condition, from a representative sample of human participants. We need a number of participants because we know that there is variability in the average RT from person to person (**between-subject** variability). Here we have 27 participants.\n",
    "\n",
    "To estimate the average RT for each condition for an individual, we would want to present many trials of each condition, in random order. We do this because there is always some trial-to-trial variability in measuring human RTs (**within-subject** variability). In this study each participant completed 40 trials in each condition. Thus we have repeated measures of RT for each participant, in each experimental condition. \n",
    "\n",
    "This experiment also had a third condition, *neutral*. On neutral trials, only the centre arrow was presented, without flankers. This condition was included to control for the fact that 5 arrows all pointing in the same direction might facilitate (speed up) responses relative to a single arrow — there might be additive, beneficial effects of congruent flankers. Comparing both the congruent and incongruent conditions to the neutral condition allows us to estimate the relative cost or benefit of flankers that are incongruent or congruent with the direction of the centre arrow. To ensure that there were as many neutral (single-arrow) as flanker (five-arrow) trials, 80 neutral trials were included per participant. \n",
    "\n",
    "So we have data from 27 participants, and approximately 160 trials per participant in total.  The nesting structure of this data set is thus trials (n=160) nested within conditions (n=3) nested within participants (n=27). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6200da2-a6dc-42f0-a8e9-45f1a9a21695",
   "metadata": {},
   "source": [
    "### Load data and check that it is loaded correctly\n",
    "\n",
    "The next step is to load the data in preparation for our exploratory\n",
    "data analysis. Then, we’ll check that it is loaded correctly.\n",
    "\n",
    "Some examples of the things we’ll look for include:\n",
    "\n",
    "-   Does the `DataFrame` have the correct number of rows and columns\n",
    "    (consistent with our expectations from the first step)?\n",
    "-   Is the first row of “data” in the `DataFrame` real data, or is it\n",
    "    column labels that were misinterpreted as data? (Similarly, are the\n",
    "    column labels actually labels, or are they the first row of data?)\n",
    "-   Are the data types of every column consistent with our expectations?\n",
    "\n",
    "At this stage, we might also do some very basic manipulation of the data\n",
    "- for example, compute some fields that are derived directly from other\n",
    "fields. (For example, suppose you have the “rt” field in seconds and\n",
    "you wanted to convert it to milisecons - you could do that here!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc3ff75-cc53-4543-b437-02a8ec37d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22866507-dc48-4849-8557-3f922e5701de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flanker_rt_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b64da-f506-4fc4-aeee-9fdf15d10e71",
   "metadata": {},
   "source": [
    "Let's look at the data\n",
    "```python \n",
    "df.sample(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60125393-7201-4fd0-8cea-ca62f468b9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5c7062-3fa3-43c3-8ca1-faca913991fe",
   "metadata": {},
   "source": [
    "### Inspect the data to make sure it is consistent with your expectations (“sanity checks”), and clean or filter the data if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101bfca-1fee-4dca-a1dd-4ca4f5db1c7b",
   "metadata": {},
   "source": [
    "Check the total number of participants in the dataset, column names, average number of trials per participant, flankers conditions \n",
    "```python\n",
    "num_participants = df['participant'].unique()\n",
    "\n",
    "avg_num_trials_per_participant = df.shape[0]/num_participants\n",
    "\n",
    "exp_conditions = df['flankers'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5692b2d-c3bd-4d29-b99f-e2c7c7c9cb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc9c390-feab-42c1-b85f-42c1dfaea322",
   "metadata": {},
   "source": [
    "### Compute descriptive statistics and explore relationships in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74366f7a-6634-40a7-9aae-b361d5603528",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ea2e9-8743-45cb-af8b-c5d1e8aebc86",
   "metadata": {},
   "source": [
    "![descriptive](images/descriptive_illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc9ff0-4821-43a7-8dee-c8d3877febaf",
   "metadata": {},
   "source": [
    "Check for missingness\n",
    "```python\n",
    "df.isnull()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d0d42-df61-4773-ac1f-71fad3806142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c07193b-1349-43ed-b8d8-a968d6d50cd4",
   "metadata": {},
   "source": [
    "Check measures of central tendency and variability as well as the range for the relevant features (columns)\n",
    "```python\n",
    "df['rt'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9c617-0474-40e8-b851-bbed0ea2960d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8783194-1cff-4d4c-8ca6-16f11a20fc37",
   "metadata": {},
   "source": [
    "* Mean and median are used to summarize the central tendency for quantitative variables\n",
    "* Mode is most helpful in describing the central tendency for categorical variables\n",
    "* The central tendency tells you part of the story. The variability in the values in your observation helps fill in the rest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc047f-a8b9-49a9-9253-0082e9599284",
   "metadata": {},
   "source": [
    "Is there anything surprising in the descriptive statistics above? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd55e1ca-e086-47e0-bcd8-9fa00dd7d035",
   "metadata": {},
   "source": [
    "Next, we visualize distribution shape for the relevant features (columns)\n",
    "\n",
    "It’s critical to know the distribution of the variables in your dataset because certain statistical approaches can only be used with certain distributions \n",
    "\n",
    "\n",
    "```python\n",
    "sns.histplot(df['rt'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44cc4d-63e9-45d3-a7ac-01fb8b05bfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0f58d1-c66c-4da6-be73-baf50f369651",
   "metadata": {},
   "source": [
    "Note that identifying the shape of the distribution can also help you identify outliers\n",
    "\n",
    "What kind of distribution does this look like? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d91d14-c86f-473d-a28d-3609c37bb4d2",
   "metadata": {},
   "source": [
    "#### Few common distributions\n",
    "![descriptive](images/distributions_illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73519284-64f5-407c-8e51-401b85bdb129",
   "metadata": {},
   "source": [
    "* A uniform distribution is one where the distribution of values is constant over the range of the variable \n",
    "* A bimodal distribution is a distribution that has two distinct modes or peaks\n",
    "* A bell-shaped distribution, also called the Gaussian or Normal distribution has the following characteristics \n",
    "    - has the shape of a bell\n",
    "    - most of the data points cluster around the mean \n",
    "    - as you move away from the mean in either direction, the frequent of data points gradually decreases\n",
    "    - the data are symmetric around the middle\n",
    "* Skewed distributions are asymmetric distributions with more values towards one end of the range than the other\n",
    "* A random distribution is when there is no apparent pattern in the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17efe6-62cc-44ad-b719-2a7dacf1ced4",
   "metadata": {},
   "source": [
    "#### Descriptive statistics by groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab88ab-97ed-4bf3-9144-41f775afca56",
   "metadata": {},
   "source": [
    "Now we can get some descriptive statistics for RT in each condition. We do this using pandas `.groupby()` method to group by flanker condition, and then we select the `rt` column for further processing by putting it in square brackets (which is pandas' way of selecting columns). Finally we chain all this with the `.describe()` method\n",
    "```python\n",
    "df.groupby('flankers')['rt'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088433c-93fb-487e-b71b-6e45300562b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3397cc-9bf2-45ef-9aae-6c9d86c5ff86",
   "metadata": {},
   "source": [
    "Note the `count` (total number of data points), standard deviation (`std`) as well as the `min` and `max` values for each condition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5903a242-c00b-4a61-a1d6-1d3a7906510c",
   "metadata": {},
   "source": [
    "Descriptive statistics are informative but they are often not enough, you shouldn’t rely solely on these statistics but should also visualize your data. \n",
    "This is best illustrated through Anscombe's Quartet\n",
    "![anscombe](images/anscombe_quartet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2bb3b-c9e8-4046-ab87-e627407ec0d1",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6750e-8df1-4082-825b-1fa525bd8640",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054d36e-ac1f-4805-ab5b-d90fc83ab98f",
   "metadata": {},
   "source": [
    "Let's look at a box plot of values in each condition:\n",
    "```python\n",
    "sns.catplot(kind='box',\n",
    "           data=df,\n",
    "           x='flankers', y='rt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95e070-d4d7-4acb-b103-3fa8aabb1487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e3eb08-51d1-45f5-9286-0dcc113bd127",
   "metadata": {},
   "source": [
    "The data show the skew that is expected of RT data — there are fundamental human performance limits on how fast a person can respond (short RTs), but the upper limit of RTs is theoretically unlimited. In the present experiment, participants actually only had a 1 s window in which to respond, so the RTs are all less than 1. Nevertheless, the data are skewed because there is a wider range of RTs above the median than below.\n",
    "\n",
    "Another thing we can see about the distribution of values is that there are many outliers (individual points in the box plot) at the long end of the RT range, but few at the short end. This is, again, a consequence of the skewed nature of the data. However, notably some of the outliers on the short end of the distributions are suspicious: human RTs in very simple tasks (like pressing a button any time a light comes on) are rarely shorter than 200 ms, yet we have a few RT values below that. So our box plots suggest that we may have some anomalous data, perhaps from trials on which someone pressed a button accidentally prior to processing the actual direction of the arrow.\n",
    "\n",
    "Finally, the box plots suggest that RTs are slowest in the incongruent condition and fastest in the congruent condition — consistent with our predictions based on past studies of the flanker effect. RTs for the neutral condition are in between the other two conditions. This suggests that perhaps both facilitation effects in the congruent condition, and interference effects in the incongruent condition, are present in the data. However, it's hard to know how large or believable those differences are, because the distributions overlap quite a bit between the three conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ab646-b8dd-459c-aa4f-eadf0d04422f",
   "metadata": {},
   "source": [
    "### Strip plot\n",
    "A strip plot is a single-axis scatter plot that is used to visualise the distribution of many individual one-dimensional values. \n",
    "\n",
    "Next let's look at a strip plot of the data, which plots each data point separately:\n",
    "```python\n",
    "sns.catplot(kind='strip',\n",
    "           data=df,\n",
    "           x='flankers', y='rt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76984c4-a27a-4986-a671-93fab1f4e649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d750e308-9f8b-4f50-96b2-f29a33361267",
   "metadata": {},
   "source": [
    "This is really less informative than the above plots, because there are so many data points! Mostly we just see big patches of the plots for each condition with lots of individual values. \n",
    "\n",
    "However, the strip plots do show us something interesting that wasn't evident in the previous plots: the very fast outlier data points are quite anomalous, even compared to the very slow outliers. That is, there are few \"fast\" data points, and they are generally quite far from the rest of the distribution of RTs. In contrast, the slower data points are more plentiful, and seem to form a rather continuous set of values, albeit more sparse than the points closer to the centres of the distributions. This suggests that the slower data points might be quite believable as real data — mosly people make faster responses, but sometimes they're a bit slower. In contrast, the strip plot gives us greater confidence that the very fast RTs should be eliminated from analysis, because they are not just slightly-faster responses than the next-fastest responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a9d4c-93ab-4a9f-8e1a-242f52fc3a30",
   "metadata": {},
   "source": [
    "### Point plot\n",
    "Finally, let's look at a point plot. \n",
    "\n",
    "Point plots show the mean for each condition, along with 95% confidence intervals (CIs) as the measure of variance. CIs are much narrower than the whiskers in box plots, because they are meant to represent our confidence in the estimate of the mean, rather than showing the overall distribution of values. In general, we can interpret conditions with non-overlapping 95% CIs as being \"believably different\" from each other, and likely to be statistically significantly different as well.\n",
    "```python\n",
    "sns.catplot(kind='point', \n",
    "           data=df,\n",
    "           x='flankers', y='rt', hue='flankers')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d8665-6de4-4b20-965e-0726e774a274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5177889b-e8eb-4a36-82da-2b55d568f898",
   "metadata": {},
   "source": [
    "## Examine individual participant data\n",
    "Now, let's use split-apply-combine to average the RTs within each individual participant (and within each condition within individuals) prior to the group-level descriptive statistics. We can do this in one line of code by chaining, combining the following steps:\n",
    "- group by both participant ID and condition (split). Note that the argument to `.groupby()` is a list containing the two columns we want to group by\n",
    "- compute the mean for each condition within each participant (apply)\n",
    "- group by condition only (combining across participants)\n",
    "- use `.describe()` to apply another computation (average across participants) and combine the output into a new table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caccdb0-1357-4cc8-b2e4-0a1820574fc0",
   "metadata": {},
   "source": [
    "```python \n",
    "df.groupby(['participant', 'flankers'])['rt'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e6f5d-0212-4514-beeb-bb8babcb441f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d5c1fff-1710-442a-a24d-999c3d69c34d",
   "metadata": {},
   "source": [
    "This is a lot of numbers to look at! Indeed, so may that pandas doesn’t show us all the rows. From what is shown, we can see that there is certainly variance in mean RTs for each individual, and in variance (as measured by standard deviation), but it’s hard to get a real sense of how much variability there is, or whether there are any participants whose data may be anomalous relative to most others.\n",
    "\n",
    "### Visualizing nested data with Seaborn\n",
    "\n",
    "Seaborn makes it easy to separate data by participants in visualization. For example, we can generate box plots as we did above, but put participant on the *x* axis, and use the `hue` kwarg to colour-code flanker condition. Because there are lots of individual participants, we add the `aspect=3` kwarg to tell Seaborn to make the plot 3x as wide as it is tall.\n",
    "```python\n",
    "sns.catplot(kind='box',\n",
    "           data=df,\n",
    "           x='participant', y='rt', hue='flankers',\n",
    "           aspect=3\n",
    "           )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359058f-6212-431e-833f-fc0bc96fcd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc01ecf3-29f5-41ea-9493-13bd8ee534fe",
   "metadata": {},
   "source": [
    "Another way to visualize so many different box plots is with Seaborn's `col` and `col_wrap` kwargs. On its own, `col=` will plot whatever variable you give it in separate columns — in our case, participants (rather than as different locations on the *x* axis, as shown above). Adding the `col_wrap` kwarg is necessary when the number of categories passed to `col` is large, as in our 27 participants. This kwarg tells Seaborn how many columns to put on one row before wrapping around to a new row. \n",
    "\n",
    "One last trick we will use is to set Seaborn's context to `talk`, to make the font size easier to read when we have so many plots. We'll set it back to `paper` after showing the plot, so our future plots aren't affected.\n",
    "```\n",
    "sns.set_context('talk')\n",
    "sns.catplot(kind='box',\n",
    "           data=df,\n",
    "           x='flankers', y='rt', col='participant', col_wrap=6,\n",
    "           )\n",
    "sns.set_context('paper')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd541cdb-c714-48ef-8687-26dec5de78f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f7fb3c6-3332-4bad-a8be-91c7861310d7",
   "metadata": {},
   "source": [
    "This plot shows us that, indeed, there is variability among participants in both the median RTs and the variance (as indicated by the length of the whiskers, and the number and range of outlier points). Encouragingly, however, each individual seems to show the expected effect, of longer RTs for incongruent than congruent flankers. It also shows us that those anomalously fast RTs we saw above are contributed only by a couple of participants, again leading us to think that these are not believable data points.\n",
    "\n",
    "Next we'll generate a strip plot, in which we colour-code the points according to which participant they are from:\n",
    "\n",
    "```python\n",
    "sns.catplot(kind='strip',\n",
    "           data=df,\n",
    "           x='flankers', y='rt', hue='participant')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e97f01-57da-40d8-ae13-23ddc3c387b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d0854a9-c7ea-453f-8658-cedf6974bef8",
   "metadata": {},
   "source": [
    "This is not a lot more useful than the strip plot above, because Seaborn draws dots for each participant over those of previous participants. So we see lots of pink in the plot above, because that is the colour used for the last participant plotted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f65d6-4f07-41f1-95f0-533d3d2d392d",
   "metadata": {},
   "source": [
    "## Appropriately dealing with repeated measures: Aggregating data by participants\n",
    "\n",
    "Because there are so many data points, and variation in both the mean and range of values between participants, it is necessary to first average (**aggregate**) within each participant and condition, prior to computing descriptive statistics or visualizing. This ensures that the variance we are examining is the **between-subjects variance**, unconfounded with **within-subjects variance**. This is primarily important in generating plots that show confidence intervals (CIs), such as point plots and bar plots, for reasons explained below.\n",
    "\n",
    "Seaborn has a way of doing this \"on the fly\" when you generate plots, using the `units=` kwarg and passing the name of the grouping variable for repeated measures (in this case, `participant`):\n",
    "\n",
    "```python\n",
    "sns.catplot(kind='point', join=False,\n",
    "           data=df, units='participant',\n",
    "           x='flankers', y='rt', hue='flankers')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f24ea6-d267-40c7-9f8c-3834db043cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ed8230-7ff9-4318-91df-8eaa365b4178",
   "metadata": {},
   "source": [
    "**This is the most important figure in this lesson**. Compared to the point plot with 95% CIs that we generated above for the aggregated data, the CIs in this plot are much larger than those we saw earlier, in the point plot for the un-aggregated data. In that previous plot, the width of the CIs was only about 0.005 s (5 ms). Here, with the CIs computed properly (as reflecting the variance across individuals), the width of the CIs is approximately 0.02 s (20 ms). While still small relative to the differences in the means, the CIs are nonetheless roughly 4x wider in the aggregated data. \n",
    "\n",
    "### Why do CIs get larger when we properly aggregate repeated measures data?\n",
    "\n",
    "We'll see below that the variance in the data actually goes down when we average within participants, as quantified by the min-max range of values, and the standard deviation. So it may seem strange that the CIs do the opposite, and get bigger. To understand this, consider how the 95% CIs are computed:\n",
    "\n",
    "$CI = 1.96 * \\frac{std}{\\sqrt n}$ \n",
    "\n",
    "CIs are computed by dividing the standard deviation ($std$) by the square root of $n$ — the number of data points used to compute the mean and standard deviation. In the un-aggregated data, this was approximately 1000 – 2000 data points for each condition. In contrast, for the aggregated data, $n$ = 27. Thus the CIs are much wider, because dividing by a larger number (1000 - 2000, rather than 27) results in a smaller number (even factoring in the differences in standard deviation, and the square root calculation). The values are multiplied by 1.96 because this is the *z* value corresponding to *p* = .05 in a normal distribution.\n",
    "\n",
    "Notably, the conclusions that we would draw from this final plot would be quite different from if we had, in error, used the first point plot generated from the un-aggregated data. The first plot made it look like RTs in the three conditions were very different from each other, with little question as to the differences between them (due to the small and non-overlapping CIs). In contrast, when the data are properly aggregated as in the above plot, the CIs for neutral overlap a lot with both of the flanker conditions, which makes us less confident in their differences. \n",
    "\n",
    "\n",
    "Recall that the neutral condition was intended to help assess whether the congruent flankers showed facilitation relative to neutral, and whether incongruent flankers showed interference relative to neutral. The fact that the neutral condition overlaps with both others, but congruent and incongruent appear significantly different, suggests that the flanker effect (congruent faster than incongruent) may actually be due to a *combination* of facilitation and interference, rather than one or the other. \n",
    "\n",
    "The interpretation of the current data set is less important here than understanding the importance of recognizing and appropriately dealing with repeated-measures data. It is critical to understand the effects of repeated measures and nesting on estimate of variance — and of the differences between measures of variance in the data (as reflected by things like standard deviation, or box plots), and estimates of our confidence in the accuracy of the mean (CIs). CIs can be used for statistical inference (i.e., is there a believable difference?), whereas the variance reflected in box plots (and histograms etc.) is more informative at the early stages of exploring and understanding your data, and diagnosing potential issues in the data that might need to be addressed prior to inference about the true patterns in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d468c81-4bef-42fe-8729-486e3cca1bc5",
   "metadata": {},
   "source": [
    "## Aggregating using Split-Apply-Combine\n",
    "\n",
    "While it's nice that Seaborn can aggregate repeated-measures data for us, that only works for generating Seaborn plots. It's also good to know how to create a DataFrame of aggregated data, which you can then use to generate tables of descriptive statistics, and eventually perform statistical tests on.\n",
    "\n",
    "To do this, we will use *two* split-apply-combine operations in sequence. In one chained command, we will:\n",
    "- split the data by participant and condition: `.groupby(['participant', 'flankers'])`\n",
    "- select the `rt` column: `['rt']`\n",
    "- apply a calculation to get mean RT for each participant/condition: `.mean()`\n",
    "- split these results by condition only, to combine across participants: `.groupby('flankers')`\n",
    "- apply descriptive statistics and combine the results in a table: `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5646f0-3efb-499e-baa1-2ea44a9e3fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db80471-9ef9-4b0e-ae0f-d80fe08dab07",
   "metadata": {},
   "source": [
    "Compare the `count`, `std`, `min`, and `max` values here to that in our first descriptive statistics table above, which we'll reproduce here for ease of comparison\n",
    "```python\n",
    "df.groupby('flankers')['rt'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510369e-ad55-4321-8599-4ce4acf35829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf8a5ff0-c67a-41f4-a21f-620377b60c4a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can see that the number of data points goes down from the total number of trials across all participants (~4200) to 27 per condition (the number of participants). The mean RTs do not actually change at all. This is expected because averaging is a linear operation, meaning that the average across all trials is the same as averaging first within participants then across trials.\n",
    "\n",
    "However, the range of values decreases when we look at the min and max values. This is a normal consequence of averaging — the most extreme values found in a set of individual data points will be reduced when we average by some grouping variables (like participant).\n",
    "\n",
    "The variance (as reflected by the standard deviation, std) gets smaller as well, for a similar reason: the variance is now among the average RTs for each participant in each condition, which have a smaller range than the raw data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30e844-646f-4212-93da-9234c40e8be0",
   "metadata": {},
   "source": [
    "### Plot data aggregated across trials\n",
    "\n",
    "Now let's re-plot the data using the same plots we did above, but now for the data averaged within participants. \n",
    "\n",
    "First let's save the aggregated data in a new DataFrame called `df_avg`. We chain the `.reset_index()` method to the end of this, because `.groupby()` sets the indexes of the DataFrame to be the grouping variables (in this case, `rt` and `flankers()`). This is ideal for looking at tables of the data (e.g., in the above, RT and condition are in bold), but index columns are not visible to Seaborn as data columns for plotting. So we use `.reset_index()` to convert `rt` and `flankers` back from indexes to regular DataFrame columns.\n",
    "\n",
    "```python\n",
    "df_avg = pd.DataFrame(df.groupby(['participant', 'flankers'])['rt'].mean()).reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd44af-c15d-442a-a9f1-5761d50920a0",
   "metadata": {},
   "source": [
    "Now let's generate a box plot of these data:\n",
    "```python\n",
    "sns.catplot(kind='box',\n",
    "           data=df_avg,\n",
    "           x='flankers', y='rt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadeb91e-81c7-4ce3-8029-d207240b134f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ee7874-cb9c-43f9-b8a9-69b7421e95c5",
   "metadata": {},
   "source": [
    "Another, somewhat confusing, thing is that the order of the conditions on the *x* axis is reversed: whereas before the order was congruent- neutral - incongruent, now neutral is last. This is a consequence of the `.reset_index()` method, which led to the conditions being re-ordered alphabetically. This highlights that its always good to pay close attention to your plot labels!\n",
    "\n",
    "Seaborn actually has an easy way to specify the order of values on a categorical axis, if you want to: using the `order=` kwarg, and passing a list of conditions in the order you want them to appear:\n",
    "\n",
    "```python\n",
    "sns.catplot(kind='box',\n",
    "           data=df_avg,\n",
    "           x='flankers', y='rt',\n",
    "           order=['congruent', 'neutral', 'incongruent'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a74e7b-0136-46dc-96f3-6d809b1bca59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec500060-3013-4e99-8f02-384d3efe390a",
   "metadata": {},
   "source": [
    "### Strip plot\n",
    "A strip plot of the data now much easier to make sense of, because we only have one point per participant in each condition\n",
    "\n",
    "```python\n",
    "sns.catplot(kind='strip',\n",
    "           data=df_avg,\n",
    "           x='flankers', y='rt', hue='participant')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fb5b0-9ac8-4317-84af-1b66e89247e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35eca4bd-40c7-4fd4-b057-56ae4ad440bc",
   "metadata": {},
   "source": [
    "### Line plot\n",
    "This makes it easier to get a sense of the variability between individuals. However, It's a bit hard to see how each individual's RT changes between the two experimental conditions. To facilitate this, let's use a point plot, which by default draws lines to join data from each individual:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb1536-3163-48f0-ac99-4b49efe585e2",
   "metadata": {},
   "source": [
    "```python\n",
    "sns.catplot(kind='point',\n",
    "           data=df_avg,\n",
    "           x='flankers', y='rt', hue='participant',\n",
    "           order=['congruent', 'neutral', 'incongruent'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe692f33-d6cd-4266-827e-3def571ff7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f880718a-d84f-4255-8735-f46c0fdfe7d9",
   "metadata": {},
   "source": [
    "You may recall that point plots typically show means and 95% CIs, but the plot above lacks CIs. This is because in the `df_avg` DataFrame, there is only one value for each participant in each condition (because we averaged across trials). If we wanted to see CIs for each individual, we could use the un-aggregated data (`df`).\n",
    "```python\n",
    "sns.catplot(kind='point',\n",
    "           data=df,\n",
    "           x='flankers', y='rt', hue='participant',\n",
    "           order=['congruent', 'neutral', 'incongruent'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed3a88-3ddc-4299-8bb1-fc7206117ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661df79d-00aa-4338-97ee-131c71eac16d",
   "metadata": {},
   "source": [
    "## Point plots aggregated across participants\n",
    "\n",
    "The CIs in the above plot don't, however, help us to make a simple inference as to whether, across all participants, there is a significant RT difference between congruent and incongruent. The data are certainly suggestive of this, because all participants show slower RTs for incongruent. But this is where a point plot with 95% CIs, across participants, is useful:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c3da3-7547-47ac-bc97-c2225a97172e",
   "metadata": {},
   "source": [
    "```python \n",
    "sns.catplot(kind='point', join=False,\n",
    "           data=df_avg,\n",
    "           x='flankers', y='rt', hue='flankers',\n",
    "           order=['congruent', 'neutral', 'incongruent'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536d288-da58-4046-8701-5d2278c88c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31290b19-2577-4aa1-937d-d534a04f2eb4",
   "metadata": {},
   "source": [
    "### Things to remember about repeated measures\n",
    "- Repeated measures occur when we take repeated samples of the same measurement. This is common in cognitive psychology and neuroscience data, because individual measurements typically include noise. Averaging across repeated measurements yields a more robust estimate of the true value for that individual\n",
    "- When we have repeated measures data, we need to be concerned about the difference between within-subjects variance, and between-subjects variance\n",
    "- Within-subjects variance is the variation within an individual, across the repeated measurements we take\n",
    "- Between-subjects variance is the variation between individuals, in the *average* response across the repeated measures taken from that individual\n",
    "- If we simply average across all trials and participants, our measures of variance will be inaccurate, because we are conflating within- and between-subjects variance\n",
    "- Conflating within-and between-subjects variance will lead to incorrect conclusions, particularly because confidence intervals and statistical tests consider the number of samples in their computations. When assessing effects across a group of participants, the number of participants is the appropriate number of samples to use. The much larger number of samples that comes from summing the number of individual trials across all participants will artificially inflate estimates of the significance of experimental effects\n",
    "- The proper way to work with repeated measures data is to first average across all trials for each experimental condition, within an individual. We call this *aggregation*\n",
    "- After we have properly aggregated the data within each individual, then we can average across participants and accurately estimate the between-subjects variance\n",
    "- Between-subject variance is typically what is important in assessing the significance of experimental manipulations\n",
    "- Proper aggregation of repeated measures data is easy using the pandas `.groupby()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdc6aa-5254-461f-9060-53d809e5ffaf",
   "metadata": {},
   "source": [
    "## Outlier Identification and Removal\n",
    "\n",
    "**Outliers** are data points that are \"significantly different\" from the majority of data points in a data set. \"Significantly different\" is in quotes here, because this does not necessarily mean we use statistical testing to define outliers, and also that there are several different definitions of \"significant\" that cam be used to identify outliers.\n",
    "\n",
    "### Tukey's method\n",
    "[John Tukey](https://en.wikipedia.org/wiki/John_Tukey), [who was a driving force in the development of exploratory data analysis](https://scholar.google.com/scholar_lookup?&journal=Exploratory+Data+Analysis&author=Tukey+J.+W.&publication_year=1977&volume=Vol.%202), defined outliers as points more than $1.5 x IQR$. Recall that IQR is the *inter-quartile range*, which captures 50% of the data points in a data set. In a box plot (which Tukey invented), the IQR is the \"box\", and 1.5 IQR are the extent of the \"whiskers\" in each direction from the median. We noted earlier that in box plots, outliers are represented as individual points in the plot, beyond the whiskers. Since Tukey invented box plots and this definition of outliers, it's not surprising that they are identical. In general, outliers defined in this way will comprise approximately 1% of the data, if the data are approximately normally distributed.\n",
    "\n",
    "![](images/boxplot_vs_pdf.png)\n",
    "\n",
    "*Image from [Jhguch](https://en.wikipedia.org/wiki/User:Jhguch) and shared under the  [Creative Commons Attribution-Share Alike 2.5 Generic](https://creativecommons.org/licenses/by-sa/2.5/deed.en) license, via Wikimedia Commons*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4802e43-25f5-4cb6-9d3a-37592f156ed1",
   "metadata": {},
   "source": [
    "### Standard scores\n",
    "\n",
    "An alternative method is to use standard scores. This is done by applying the ***z* transform** to the data. This transform's formula is:\n",
    "\n",
    "$$z = {(x - \\mu) \\over \\sigma} $$\n",
    "\n",
    "Where $x$ is an individual data point, $\\mu$ is the mean of the data set, and $\\sigma$ is the standard deviation. In other words, the *z* transform takes a data set and transforms it so that its mean is zero (by subtracting the mean from every value), and its standard deviation is 1. \n",
    "\n",
    "Put another way, after we apply a *z* transform to a data set, the numerical values in the data set are not in their original units (be that milliseconds, or dollars, or whatever) but in units of standard deviations. So in a *z* transformed data set, a data point with a value of 1 would have had an original value that was 1 standard deviation from the mean. This is where the \"standard\" in \"standard scores\" comes from.\n",
    "\n",
    "Applying a *z* transform is also called *normalizing* the data set, because the *z* transform assumes that the data come from a normal distribution (also known as a Gaussian distribution, or the *bell curve*). The nice thing about standardizing a data set is that the values have fairly straightforward interpretations. In a normal distribution:\n",
    "- 68.27% of all values fall within ±1 standard deviation of the mean ($1 \\sigma$),\n",
    "- 95.45% of all values fall within ±2 standard deviations of the mean ($2 \\sigma$), and\n",
    "- 99.73% of all values fall within ±3 standard deviations of the mean ($3 \\sigma$)\n",
    "\n",
    "<img alt=\"M. W. Toews, CC BY 2.5 &lt;https://creativecommons.org/licenses/by/2.5&gt;, via Wikimedia Commons\" src=\"./images/standard_deviation_diagram.svg\" width=500>\n",
    "\n",
    "*Image from M. W. Toews, and shared under the  [Creative Commons Attribution-Share Alike 2.5 Generic](https://creativecommons.org/licenses/by-sa/2.5/deed.en) license, via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Standard_deviation_diagram_micro.svg)*\n",
    "\n",
    "This means that if we define outliers as those values *z* > 3 or *z* < -3, then we will tend to reject about 0.25% of a data set. Sometimes, *z* ±2.5 $\\sigma$ is used instead. This will tend to reject more data points (typically around 2%). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e250d73-352b-447e-ad93-9f9e8fd9b2bd",
   "metadata": {},
   "source": [
    "### Idenfity outliers in a DataFrame\n",
    "\n",
    "To define values based on the IQR, we first need to calculate the IQR. pandas doesn't have a method for this specifically, but we can use the pandas `.quantile()` method with the argument 0.25 to reference the lower end of the IQR (the 0.25 quantile means the point below which 25% of data values lie), and 0.75 for the upper end of the IQR. Since IQR is defined as the range between the 25th and 75th quantiles, we can compute it by subtracting the difference between the two:\n",
    "\n",
    "~~~python\n",
    "q1 = df['rt'].quantile(0.25)\n",
    "q3 = df['rt'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459982f-16db-41fa-970f-76b37efbf487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c37736f-288d-4592-8451-8838514dba7e",
   "metadata": {},
   "source": [
    "The variable `iqr` represents the size of the box in the box plot of the data. Recall that our definition of outliers is 1.5 x IQR — the length of the whiskers in the box plot. \n",
    "\n",
    "We can now define the threshold for values we well call \"outliers\" (i.e., the length of the whiskers) based on `iqr`:\n",
    "\n",
    "~~~python\n",
    "out_low = q1 - 1.5 * iqr\n",
    "out_high = q3 + 1.5 * iqr\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24408b3-b178-4d95-967f-187d13469747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4be41553-f001-4743-b22f-b63b7e91fb17",
   "metadata": {},
   "source": [
    "So `out_low` (the end of the bottom whisker) is 1.5 x IQR below q1 (the lower end of the box), and likewise for `out_high`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d86b8-52fb-4c2b-9e7a-3385eb8b3e5e",
   "metadata": {},
   "source": [
    "Recall from the pandas lesson that we can select values in a DataFrame using a Boolean mask. We can do that here to identify the rows of the DataFrame where the RT values are lower than 1.5 x IQR:\n",
    "\n",
    "~~~python\n",
    "df.loc[:, 'rt'] < out_low\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00452362-c39d-4ff7-8a63-ee7f58ab41ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06329586-9ce2-4fc9-a81d-82c5bf11ab04",
   "metadata": {},
   "source": [
    "The result will have values of `True` for those data points that are \"low\" outliers, and `False` for all other data points. We can count the number of these by passing the mask to `np.sum()` (since `True` = `1` and `False` = `0`)\n",
    "\n",
    "~~~python\n",
    "np.sum(df.loc[:, 'rt'] < out_low)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cb36b-1701-4e74-b103-f2762cd2041a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c05636-a71f-449a-b3c3-e8c47d71aa2d",
   "metadata": {},
   "source": [
    "We can do the same to identify outliers at the high end of the range of values, using the `>` operator this time:\n",
    "\n",
    "~~~python\n",
    "np.sum(df.loc[:, 'rt'] > out_high)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62785e0f-21fe-4c4f-bae6-6d8b6f5eb263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08f14c28-03c4-4aab-a228-4818e79303df",
   "metadata": {},
   "source": [
    "Consistent with what we saw in the box plot, there are more outliers at the high (slow RT) end of the distribution than at the low (fast RT) end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754ad60-5c0b-4947-8448-7fce43633f7d",
   "metadata": {},
   "source": [
    "#### Marking data points as outliers\n",
    "\n",
    "Now let's make a column in `df` called `outliers_tukey` that is a Boolean mask: values of `True` in rows with outlier RT values, and `False` for all other rows. \n",
    "\n",
    "To do this, we want to combine the two masking operations above `< out_low` and `> out_high`. We can do that using the OR `|` operator, as long as we include each of our masking operations in parentheses (this last bit is important, but easy to forget!):\n",
    "\n",
    "~~~python\n",
    "\n",
    "(df.loc[:, 'rt'] < out_low) | (df.loc[:, 'rt'] > out_high)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7f2ed-23ba-492c-bbfb-0d5404ed2a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87f7f99-e180-4c12-9356-c6aa671ff86a",
   "metadata": {},
   "source": [
    "It's a bit hard to confirm that this works from the output above, but if we pass that whole expression to `np.sum()` we can see that the number of all `True` values is the same as the total of the `out_low` and `out_high` values reported above:\n",
    "\n",
    "~~~python\n",
    "np.sum((df.loc[:, 'rt'] < out_low) | (df.loc[:, 'rt'] > out_high))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577e21b-3065-4b09-a9a7-d96755c9bbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9bcf8c1-6e58-4c33-b35d-d0632b35955e",
   "metadata": {},
   "source": [
    "To actually use this expression to create a new column, we just have to assign the result to a new column name in `df`:\n",
    "\n",
    "~~~python\n",
    "df['outliers_tukey'] = (df.loc[:, 'rt'] < out_low) | (df.loc[:, 'rt'] > out_high)\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5e7af-2ec1-41f0-b9dc-16207e3bbd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58820a2d-b92c-4e02-b059-607facdb5a0e",
   "metadata": {},
   "source": [
    "And double-check the number, using the pandas `.sum()` method:\n",
    "\n",
    "~~~python\n",
    "df['outliers_tukey'].sum()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507b30c-0518-4dd4-bfda-27659f051805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2afbf5df-6690-4985-8ad6-51bee17c2ca4",
   "metadata": {},
   "source": [
    "### Standard scores (*z* transform)\n",
    "\n",
    "We can convert scores to standard scores very easily, using the `zscore()` function in `scipy.stats`:\n",
    "\n",
    "~~~python\n",
    "from scipy import stats\n",
    "\n",
    "df['rt_z'] = stats.zscore(df['rt'])\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d407c-5e0b-4e48-b229-8a79378ca8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7186c19c-f54d-4a36-bbf0-7c5ddde20565",
   "metadata": {},
   "source": [
    "Now we can identify outliers as those rows where `rt_z > 2.5` or `rt_z < -2.5`. We'll define a variable `z_thresh` because that way we can later change it to a different value (like 3) if we desire.\n",
    "~~~python\n",
    "z_thresh = 2.5\n",
    "(df['rt_z'] > z_thresh) | (df['rt_z'] < z_thresh)\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bb43a-f3d5-4d5b-9ff2-9452951253a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3f814ae-d0d9-410c-82a8-eb9911838963",
   "metadata": {},
   "source": [
    "More simply, we can take the absolute value of *z* (which ignores the `-` sign):\n",
    "~~~python\n",
    "np.abs(df['rt_z']) > z_thresh\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c143b11-5dd6-48d7-9daa-58acc28c53f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82a8f269-066c-4d5b-9a28-5b3647095573",
   "metadata": {},
   "source": [
    "The number of outliers identified this way is:\n",
    "\n",
    "~~~python\n",
    "np.sum(np.abs(df['rt_z']) > z_thresh)\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960cd9e-a563-4980-ba0f-fe9c3e2a69b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf5ff6c-6ca1-4394-914a-2ea8d35a6083",
   "metadata": {},
   "source": [
    "#### Write column of standard score outliers\n",
    "Now we will add a column marking outliers as defined this way, similarly to what we did above for the Tukey method:\n",
    "\n",
    "~~~python\n",
    "df['outliers_z'] = np.abs(df['rt_z']) > 3\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b0611-b221-4a3a-96e8-256bba243ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "331ec393-0225-404a-897f-9c9daa3863a2",
   "metadata": {},
   "source": [
    "### About this notebook\n",
    "\n",
    "A lot of the content here is directly adapted from Wallisch'sNeural Data Science Educational Materials (https://github.com/neural-data-science)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
